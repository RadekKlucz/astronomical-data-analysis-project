---
title: "Astronomical data project"
author: "Radosław Kluczewski"
date: "26.01.2022"
output: 
  html_document: default
  pdf_document: default
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

\section{Introduction to Asteroids data}

In this short data project using R language Firstly it has been loaded data form AstroStatistics page. After that, the basic statistics are presented below:

```{r include = FALSE}
# Load the required libraries
library(nortest)
library(outliers)

# Set working directory. If you don't know the path, enter pwd in the terminal to find your path
setwd("C:/Users/Lenovo/Desktop/Github/R-project/main")

# Load data with the file from data folder
asteroids <- read.table("./data/asteroids.txt", header = T)

# Sort data using second column
asteroids_sorted <- asteroids[order(asteroids$Dens),]

# Assign columns
names <- asteroids_sorted[, 1]
densinity <- asteroids_sorted[, 2]
error <- asteroids_sorted[, 3]
```

```{r include=TRUE}
summary(asteroids)
```

The standard deviation \$ \\ sigma \$ has also been calculated and will be used in the following median standard error formula:

\begin{equation}
    SE_{me}=\frac{1,253\cdot \sigma}{\sqrt{N}}.
    \label{wz1}
\end{equation}

The results are presented below after substituting them to the above formula, where for the dens and err columns:

```{r include=FALSE}
# Clculate standard deviation
standard_deviation_densinity <- sd(densinity)
standard_deviation_err <- sd(error)

# Calculate median standard error
se_densinity <- (standard_deviation_densinity * 1.253) / sqrt(26)
se_error <- (standard_deviation_err * 1.253) / sqrt(26)
```

```{r include=TRUE}
se_densinity
se_error
```

The figures below show the distribution of the data where errors are also included:

```{r figure 1}
graph_data <-
  dotchart(
    densinity,
    labels = names,
    cex = 0.9,
    xlab = expression(Densinity ~ (g / cm ^ 3))
  )

print(graph_data)
```

A drawing showing the density of individual asteroids. As can be seen, the highest density of data occurs around densities with values from 1 to 3. Very high densities were observed for the remaining data, which may raise suspicions. In order to check if the high-density data is true, the graph with errors was drawn, which is presented below:

```{r figure 2}
graph_errors <-
  plot(
    densinity,
    ylim = c(0, 8),
    xlab = "Asteroids",
    ylab = expression(Densinity ~ (g / cm ^ 3)),
    pch = 20
  ) + grid()

num <- seq(1, length(densinity))
segments(num, densinity + error, num, densinity - error)

print(graph_errors)
```

The chart above shows very high uncertainties for large points densities. So, these points may not necessarily be so large density values. The last graph drawn is the comparison distribution of asteroid density to the distribution of errors in their measurements. This chart allows you to check whether the data is of similar density or not. In addition, it allows you to determine the size of the errors compared to the measurements densities and whether these errors are similar or outlier.

```{r figure 3}
graph_comprasion <-
  boxplot(
    asteroids[, 2:3],
    varwidth = T,
    notch = T,
    xlab = "Asteroids",
    ylab = "Densinity
",
pars = list(
  boxwex = 0.3,
  boxlwd = 1.5,
  whisklwd = 1.5,
  staplelwd = 1.5,
  outlwd = 1.5,
  font = 2
)
  ) + grid()

print(graph_comprasion)
```

As we can read from the drawing, the data has a similar density, a errors are similar to each other. 

To check whether the data can be described by a normal distribution two tests were decided on:

**Kolmogorov-Smirnov test:**

```{r include=TRUE}
lillie.test(dens)
lillie.test(err)
```

This test is one of the best-known collective tests on normality, where he tests the null hypothesis that the decomposition of our variable is close to normal. As a test statistic we accept: 

\begin{equation}
    D_n=\sup_x|F_0(x)-S_n(x)|,
    \label{wz2}
\end{equation} 

where $ s_n (x) $ is the empirical difference which is based on the sample order as follows:

\begin{equation}
    F_n(x)=\frac{1}{n}\sum_{i=1}^n I_{X_i\leqslant x},
    \label{wz3}
\end{equation} 
where: $ X_i $ is the value of the X variable for the i-th observation. $ I_{X_i \leqslant x} $ is a characteristic function of the receiving set value one if $ X_i \leqslant x $ and zero otherwise. Big the statistics values indicate a large discrepancy in the distribution function $ F_0 $ and $ S_n $, so we construct a right-hand critical area. If the value of $ D_n $ falls into the critical area, we reject the null hypothesis on adopted significance level.

Assuming the significance level of $ \alpha = 0.05 $ and comparing go with the obtained p-value, we can say whether the hypothesis can be accept or reject. For density, the hypothesis is correct, because this value is much greater than the assumed value $ \alpha $, while for uncertainty we reject the hypothesis because value p-value is much smaller than $ \alpha $.

**Shapiro-Wilk test:**

```{r include=TRUE}
shapiro.test(densinity)
shapiro.test(error)
```

This test verifies that the sample is from a population with a distribution normal. The test statistic is:
\begin{equation}
    W=\frac{(\sum_{i=1}^n a_i x_{(i)})^2}{\sum_{i=1}^n(x_i-\overline{x})^2},
    \label{wz4}
\end{equation} 
where: $ x_i $ is $ i$ - the smallest number in the sample, $ \overline {x} $ is the sample mean, while $ a_i $ is expressed as
pattern: $(a_1 ,\ldots ,a_n)=\frac{m ^ T V ^ {-1}}{C}$. $C$ from the previous one of the formula is the norm of the vector, which is described by the formula: $C=||m ^ T V ^ {-1}||=\sqrt{m ^ T V ^ {-1} V ^ {-1} m}$, gdzie $m=(m_1, \ldots, m_n) ^ T$ includes observations for non-decreasing values.

The null hypothesis is derived from samples from a normally distributed population. For the previously adopted significance level, we can say that We can assume that the hypothesis for the density of asteriods is correct, while the hypothesis for uncertainty must be rejected because it is much less p-value.

Based on the Dixon and Grubb tests, it was checked whether in data, there are outliers. Outliers it points where the measurement may be the result of a gross error. The first test is the Dixon test, the results of which were presented below:

```{r include=TRUE}
dixon.test(densinity)
```

The Dixon Test is a test to check whether a sample contains data resulting from committing a gross error. The test statistic is: $ Q = \mathrm {\frac{gap}{range}}, $ where gap is the module from the difference between the suspect measurement and the value of the closest measurement. Range is the difference between the largest value of the sample and the smallest value of z samples.

Another test for detecting a gross error with an error is the test Grubbs, which consists in defining the $ H_0: $ hypothesis of no deviation
in the dataset and $ H_a: $ that is, is there a risk of a deviation in dataset. The test statistic is defined as:

\begin{equation}
    G=\frac{max|X_i - \overline{X}|}{\sigma},
    \label{wz5}
\end{equation} 

where $ \overline{X} $ - mean, $ \sigma $ - deviation standard. The Grubbs statistic is considered to be the greatest deviation from the mean in a normally distributed set. The test results are presented as follows:

```{r}
grubbs.test(dens)
```

Analyzing the test results, it can be concluded that we can not do any of the points considered a gross mistake. Especially the points that have the highest density.

\section{Globular clusters}

```{r include=FALSE}
# Load globular clusters data from two files
galaxies_M31 <- read.table('./data/GlobClus_M31.dat', header = T)
galaxies_MW <- read.table('./data/GlobClus_MWG.dat', header = T)

# Assing variables
m_31 <- galaxies_M31[,2]  ; 
milky_way <- galaxies_MW[,2]
```

Below are the statistics for two datasets, where the first dataset is observations of globular clusters in the Milky Way:

```{r}
summary(galaxies_MW)
```

while the second is observations of the globular clusters in M31:

```{r}
summary(galaxies_2)
```

The data distributions for which the decision was made are presented below draw histograms for graphical representation the frequency of occurrence of brightness in a given range.

```{r figure 4}
histogram_milky_way <- hist(milky_way)
histogram_m_31 <- hist(m_31)

print(histogram_milky_way)
print(histogram_m_31)
```

It can be seen from the graphs that the brightness value is in both histograms completely different. If you want to present the distributions in one graph, you should take into account the correction by subtracting the difference of the medians of the Milky Way and M31. In for this purpose, the means were calculated and then subtracted from each other:
```{r include=FALSE}
module <- median(milky_way)-median(m_31)
print(module)
```

Efektem będzie otrzymanie podobnego poziomu jasności, który jest
obserwowalny w naszej Galaktyce. Wyniki porównania wykresów zostały
przedstawione poniżej:

```{r}
plot(ecdf(MW),cex.points=0,verticals=T, main="Empiryczne dystrybuanty", col="green")
plot(ecdf(M31+module),cex.points=0,verticals=T,add=T,main="Empiryczne dystrybuanty", col="red") 
legend(-8,0.2,legend = c("Droga Mleczna","M31"),col = c("green","red"),lty = 1,cex=0.8)
```

c)  Wynik wartości **module** porównano z wynikiem testu rang
    Wilcoxon'a, który został obliczony poniżej:

```{r}
wilcox.test(MW,M31+module)
```

Jak można zauważyć wartości wyznaczone za pomocą median oraz testu są
zbliżone. Tak więc moża przyjąść, iż różnica median jako przesunięcie
jest zadowalająco wystarczające.

d)  Q-Q -- wykres kwantyl-kwantyl służy między innymi do porównania, czy
    dystrybuancja danych jest zgodna z modelem. Dwuwymiarowy wykres
    zmiennych przedstawia punkty, które powstają na wykresie w wyniku
    dwóch odpowiadających sobie wartości kwantyli zmiennych losowych ich
    rozkładu. warto zauważyć, że jeśli wszystkie punkty odpowadają lini
    prostej to zmienne losowe na wykresie są opisane tym samym
    rozkładem. Procedura utworzenia wykresu przedstawia się
    następująco:\

    ```{=tex}
    \begin{itemize}
    \item porządkowanie rosnąco residuł, które są kantylami empirycznymi,
    \item obliczenie rzędów kwantyli,
    \item obliczenie kwantyli teoretycznych,
    \item sortowanie residuł rosnąco dla drugiego zestawu danych,
    \item zestawienie kwantyli n wykresie. 
    \end{itemize}
    ```

Poniżej zostały zaprezentowane wykresy kwantyl kwantyl:

```{r}
qqnorm(MW, pch=20, cex.axis=1.3, cex.lab=1.3, main="")
qqline(MW, lty=2, lwd=1.5)
```

Oś OY powyższego wykresu przedstawia empiryczną dystrybucję jasności
gromad w Drodze Mlecznej, natomiast oś OX teoretyczną dystrybucję
rozkładu normalnego. Jak można zauważyć kwantyle empiryczne zgadzają się
z modelem teoretycznym.

```{r}
qqnorm(M31, pch=20, cex.axis=1.3, cex.lab=1.3, main="")
qqline(M31, lty=2, lwd=1.5)
```

Analogicznie jak poprzednio oś OY powyższego wykresu przedstawia
empiryczną dystrybucję jasności gromad w M31, natomiast oś OX
teoretyczną dystrybucję rozkładu normalnego. Można również zauważyć, iż
model teoretyczny nie pokrywa się z niższymi wartościami.

Porównując dystrybuancję dwóch zestawów danych otrzymujemy nastepujący
wykres:

```{r}
qqplot(M31,MW, pch=20, cex.axis=1.3, cex.lab=1.3, main="", xlab = "M31", ylab = "Droga Mleczna")
```

W powyższym przypadku na osiach są empiryczne dystrybucje jasności
gromad w Drodze Mlecznej i w M31. Na powyższym rysunku możemy
zaobserwować nieliniowy trend, który prowadzi do wniosku, iż rozkłady
jasności obu galaktyk są różne.

e)  W celu potwierdzenia powyższego wniosku należy przeprowadzić
    nastepujący test:

```{r}
ks.test(MW, M31+module)
```

Statystyka testu została opisana w poprzednim zadaniu. Dla poziomu
istotności $\alpha=0.05$ hioptezę należałoby odrzucić, ale ponieważ
poziom istotności możemy przyjąść również na poziomie $\alpha=0.01$ nie
mamy pewności co do poprawności odrzucenia hipotezy.

\section{Zadanie 3}

a)  Estymator zgodny, który jest nieobciążony oraz najefektywniejszy
    wartości przeciętnej to wartość średnia. Poniżej została
    przedstwiona wartość obliczonej średniej:

```{r include=FALSE}
library(MASS)
Height <- survey$Height 
```

```{r}
Estym <- mean(Height, na.rm = T)
Estym
```

b)  Dla nieznanego odchylenia standargowego oraz nieznanej wartości
    przeciętnej stosujemy statystykę studenta. Szukam wartość błędu przy
    przedziale ufności 95%, gdzie wykonuję następujące obliczenia:

```{r}
#rozkład studenta
s2 <- sd(Height, na.rm = T)
n <- length(Height)
t <- qt(0.975, n-1)
t
#przedział ufnosci 
Q1=qt(0.05/2, 237-1)*s2/sqrt(n)+ Estym 
Q1
Q2=qt(1-0.05/2, 237-1)*s2/sqrt(n)+ Estym
Q2
```

Ostatecznie przedziałem ufności jest wartość: $$[171.1207; 173.641],$$
natomiast wartość średnia wraz z błędem pochodzącym z tego przedziału
to: $$172.38\pm 1.34 [cm].$$

c)  W celu sprawdzenia hipotezy zerowej, czyli czy studenci palą
    niezależnie od ilości ćwiczeń zastosowano test chi-kwadrat.
    Statystyka opisująca ten test to: \begin{equation}
    \label{wz6}
    \chi^2=\sum_{i=1}^r \sum_{k=1}^s \frac{(n_{ik}-n\cdot p_{ik})^2}{n\cdot p_{ik}},
    \end{equation} gdzie: $n_{ik}$ - liczności odpowiadające danej parze
    kategorii, r=3 -liczba kategorii częstotliwości palenia, s=4 -
    liczba kategorii częstości ćwiczeń, n - suma $n_{ik}$ oraz $p_{ik}$
    które jest obliczane ze wzoru: \begin{equation}
    p_{ik}=p_{i.}p_{.k}=\frac{n_{i.}}{n}\cdot \frac{n_{.k}}{k}.
    \label{wz7}
    \end{equation} W sumie tatystyka ma 6 stopni swobody, natomiast
    obszar krytyczny jest prawostronny. Otrzymano nastepujący wynik
    testu chi-kwadrat:

```{r include=FALSE}
Exer <- survey$Exer
Smoke <- survey$Smoke
Table_Smoke <- table(survey$Exer, survey$Smoke)
Table_Smoke
```

```{r}
chisq.test(Exer, Smoke)
```

Z wyniku testu można stwiedzić, iż dla poziomu istotności $\alpha=0.05$
nie mamy podstaw do odrzucenia hipotezy zerowej.

\section{Zadanie 4}

a)  W celu dopasowania regresji liniowej zostały wykonane następujące
    polecenia:

```{r}
x <- faithful$eruptions
y <- faithful$waiting
regline <- lm(x~y)
summary(regline)
plot(x~y, ylab = "Długość erupcji [min]", xlab = "Czas oczekiwania na następną erupcję [min]")
abline(regline,lwd=2,col=2)

```

Powyżej zostały przedstawione statystyki oraz wykres zależności długości
erupcji od czasu oczekiwania na kolejną erupcję wraz z dopasowaną prostą
za pomocą regresji liniowej. Wartościami parametrów dopasowania dla
prostej: \begin{equation}
y=a\cdot x + b,
\label{wz8}
\end{equation} są między innymi:

```{=tex}
\begin{itemize}
\item $a=0.0756\pm 0.0023$,
\item $b=-1.87\pm 0.17.$
\end{itemize}
```
Do oszacowania czasu trwania następnej erupcji wykorzystano powyższy
wzór wraz z współczynnikami dopasowania, gdzie $x=80$ min. Po
podstawieniu otrzymano następujący wynik: $$4.18\pm 0.36.$$

b)  Poniżej zostały wyrysowany wykres residuł dopasowanej regresji:

```{r}
plot(regline$residuals)
```

Jak moża zauażyć zastosowany model regresji liniowej jest poprawny,
ponieważ dane są rozproszone oraz nie wykazują żadnego trendu.

c)  Kryteria **Akaike** oraz **Bayesowskie** stosuje się w celu
    porównania zastosowanych modeli do danych. Wartości uzyskane z tych
    kryteriów są estymatorami błędu oraz zgodności próbek z modelem. Ich
    wartość może wskazać, który z modeli jest lepszym wyborem, gdzie
    niższa wartość oznacza, iż model dla poszczególnych danych jest
    lepszy. Poniżej zaprezentowano wartości tych kryteriów dla regresji
    liniowej.

```{r}
AIC(regline)
BIC(regline)
```

d)  Korzystając z 95% poziomu ufności średniego czasu trwania erupcji
    dla czasu 80 min zostały wyznaczone za pomocą funkcji predict
    wartości przewidywane y. Poniżej przedstawiono wyniki działania
    funkcji:

```{r}
regline1 <- lm(eruptions~waiting,data=faithful)
time80=predict(regline1,data.frame(waiting=c(80)),interval = "confidence")
print(time80)
```

Ostatecznie odczytanym z powyższych wartości jest przedział ufności:
$(4.1; 4.25)$.
