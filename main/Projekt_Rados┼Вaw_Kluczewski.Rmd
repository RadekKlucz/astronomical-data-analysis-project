---
title: "Projekt z języka R"
author: "Radosław Kluczewski"
date: "26.01.2022"
output: pdf_document
---
\section{Zadanie 1}

Do wykonania pierwszego zadania zostały użyte dane ze strony AstroStatistics. 
```{r include = FALSE}
asteroids <- read.table("./data/asteroids.txt", header = T)
asteroids <- asteroids[order(asteroids$Dens),]
names <- asteroids[, 1]
dens <- asteroids[, 2]
err <- asteroids[, 3]
```
a) W celu uzyskania podstawowych statystyk, które opisują dane zostało wykonane nastepujące polecenie:
```{r}
summary(asteroids)
```
Zostało również obliczone odchylenie standardowe $\sigma$, które zostanie wykorzystane w następującym wzorze na błąd standardowy mediany: 
\begin{equation}
\label{wz1}
SE_{me}=\frac{1,253\cdot \sigma}{\sqrt{N}}.
\end{equation}
Poniżej zostały zaprezentowane wyniki po podstawieniu do powyższego wzoru, gdzie dla kolumny dens oraz err:
```{r include = FALSE}
S1 <- sd(dens)
S2 <- sd(err)
SE1 <- (S1 * 1.253) / (sqrt(26)) #median error
SE2 <- (S2 * 1.253) / (sqrt(26))
```
```{r}
SE1
SE2
```
b) Na poniższych rysunkach pokazano rozkład danych, gdzie uwzględniono również błędy:
```{r}
dotchart(dens, labels = names, cex = 0.9, xlab = expression(Gęstość ~ (g / cm ^ 3)))
```

Rysunek przedstawiający gęstość poszczególnych asteroid. Jak można zauważyć największe zagęszczenie danych występuje w okolicach gęstości o wartościach od 1 do 3. Dla pozostałych danych zaobserwowano bardzo duże gęstości co może budzić podejrzenia. W celu sprawdzenia, czy dane o dużej gęstości są prawdziwe wyrysowano wykres z błędami, który został przedstawiony poniżej:
```{r warning=FALSE}
plot(dens, ylim = c(0, 8), xlab = "Asteroidy", ylab = expression(Gęstość ~ (g / cm ^ 3)), pch = 20)
num <- seq(1, length(dens))
segments(num, dens + err, num, dens - err)
```

Powyższy wykres pokazuje bardzo duże niepewności dla punktów o dużch gęstościach. Tak więc niekoniecznie punkty te mogą przyjmować tak duże wartości gęstości. Ostatnim wyrysowanym wykresem jest porównanie rozkładu gęstości asteroid do rozkładu błędów ich pomiarów. Wykres ten pozwala na sprawdzenie, czy dane mają zbliżoną gęstość lub nie. Dodatkowo pozwala określić jak duże są błędy w prównaniu do pomiarów gęstości i czy te błędy są do siebie zbliżone lub czy są odstające.
```{r warning=FALSE}
boxplot(asteroids[, 2:3], varwidth = T, notch = T, xlab = "Asteroidy", ylab = "Gęstość", pars = list(boxwex = 0.3, boxlwd = 1.5, whisklwd = 1.5, staplelwd = 1.5, outlwd = 1.5, font = 2))
```

Jak możemy odczytać z rysunku dane mają zbliżoną do siebie gestość, a błędy są do siebie zbliżone. 

c) W celu sprawdzenia, czy dane można opisać rozkładem normalnym zdecydowano się na dwa testy: 
```{r include = FALSE}
library(nortest)
library(outliers)
```
**Test Kołmogorowa-Smirnowa:**
```{r}
lillie.test(dens)
lillie.test(err)
```

Test ten jest jednym z najbardziej znanych testów zbiorczych na normalność, gdzie testuje on hipotezę zerową o tym, że rozkład naszej zmiennej jest zbliżony do normalnego. Jako statystykę testową przyjmujemy: 
\begin{equation}
D_n=\sup_x|F_0(x)-S_n(x)|,
\label{wz2}
\end{equation}
gdzie $s_n(x)$ to dystybuanta empiryczna, która jest usatlona na podstawie uporządkowania próbki nastepująco: 
\begin{equation}
F_n(x)=\frac{1}{n}\sum_{i=1}^n I_{X_i\leqslant x},
\label{wz3}
\end{equation}
gdzie: $X_i$ to wartość zmiennej X dla i-tej obserwacji. $I_{X_i\leqslant x}$ to funkcja charakterystyczna zbioru przyjmująca wartość jeden gdy $X_i\leqslant x$ i zero w przeciwnym wypadku. Duże wartości statystyki świadczą o dużej rozbieżności dystrybuanty $F_0$ i $S_n$, zatem konstruujemy prawostronny obszar krytyczny. Jeśli wartość $D_n$ wpadnie w obszar krytyczny to hipotezę zerową odrzucamy na przyjętym poziomie istotności. 

Przyjmując poziom istotności na poziomie $\alpha=0.05$ oraz porównując go z otrzymaną wartością p-value możemy stwierdzić, czy hipotezę można przyjąć lub odrzucić. Dla gęstości hipotezę możemy uznać za poprawną, ponieważ wartość ta jest znacznie większa od przyjętej wartości $\alpha$, natomiast dla niepewności hipotezę odrzucamy, ponieważ wartość p-value jest znacznie mniejsza od $\alpha$. 

**Test Shapiro-Wilka:**
```{r}
shapiro.test(dens)
shapiro.test(err)
```
Test ten pozwala sprawdzić, czy próba pochodzi z populacji o rozkładzie normalnym. Statystyką testową jest: 
\begin{equation}
W=\frac{(\sum_{i=1}^n a_i x_{(i)})^2}{\sum_{i=1}^n(x_i-\overline{x})^2},
\label{wz4}
\end{equation}
gdzie: $x_i$ jest $i$-tą najmniejszą liczbą w próbce, $\overline{x}$ to średnia z próbki, natomiast $a_i$ wyrażaja się przez wzór: $(a_1,\ldots,a_n)=\frac{m^T V^{-1}}{C}$. $C$ z wcześniejszego wzoru to norma wektora, która jest opisana wzorem: $C=||m^TV^{-1}||=\sqrt{m^T V^{-1}V^{-1}m}$, gdzie $m=(m_1,\ldots,m_n)^T$ zawiera obserwacje dla wartości niemalejących.  

Hipotezą zerową to pochodznie próby z populacji o rozkładzie normalnym. Dla wcześciej przyjętego poziomu istotności możemy stwierdzić, że hipoteze dla gęstości asteriod możemy przyjąść za słuszną, natomiast hipotezę dla niepewności należy odrzucić z powodu znacznie mniejszej wartości p-value.

d) Na podstawie testów Dixon’a i Grubb’a zostało sprawdzone, czy w danych znajdują się punkty, które są outliersami. Outliersy to punkty, dla których pomiar może być wynikiem błedu grubego. Pierwszym testem jest test Dixona, którego wyniki zostały zaprezentowane poniżej: 
```{r}
dixon.test(dens)
```
Test Dixona to test służących do sprawdzenia, czy próbka zawiera dane powstałe w wyniku popełnienia błędu grubego. Statystyka testowa to: $Q=\mathrm{\frac{gap}{range}},$ 
gdzie gap to moduł z różnicy pomiędzy podejrzanym pomiarem, a wartością najbliższego pomiaru. Range jest różnicą pomiędzy największą wartości z próbki, a najmniejszą wartościa z próbki.

Kolejnym testem na wykrycie błędu grubego obarczonego blędem jest test Grubbs'a, który polega na zdefiniowaniu hipotezy $H_0:$ o braku odchyleń w zbiorze danych oraz $H_a:$ czyli, czy istnieje ryzyko odchylenia w zbiorze danych. Statystyka testowa jest określona jako: 
\begin{equation}
G=\frac{max|X_i-\overline{X}|}{\sigma},
\label{wz5}
\end{equation}
gdzie $\overline{X}$ - średnia, $\sigma$ - odchylenie standardowe. Statystykę Grubbsa uznaje się największe odchylenie od średniej w zbiorze o rozkładzie normalnym. Wyniki testu prezentują się następująco:
```{r}
grubbs.test(dens)
```
Analizujac wyniki testów można stwierdzić, że żaden punkt z nie możemy uznać za błąd gruby. Szczególnie punkty, które mają największą gęstość. 

\section{Zadanie 2}

```{r include = FALSE}
galaxies1 <- read.table('./data/GlobClus_M31.dat', header = T)
galaxies2 <- read.table('./data/GlobClus_MWG.dat', header = T)
M31 <- galaxies1[,2]  ; MW <- galaxies2[,2]
```
a) Poniżej zaprazentowano statystyki dla dwóch zestawów danych, gdzie pierwszym zestawem danych są obserwacje gromad kulistych w Drodze Mlecznej:
```{r}
summary(galaxies1)
```
natomiast drugim są obserwacje gromad kulistych w M31:
```{r}
summary(galaxies2)
```
b) Poniżej zaprezentowano rozkłady danych, dla których zdecydowano się wyrysować histogramy w celu przedstawienia graficznego częstotliwości występowania jasności w danym przedziale.
```{r}
H1 <- hist(MW)
H2 <- hist(M31)
```

Z wykresów można zauważyć, iż wartość jasności jest na obu histogramach całkowicie różna. Chcąc przedstawić rozkłady na jednym wykresie należy uwzględnić poprawkę odejmując różnicę median Drogi Mlecznej oraz M31. W tym celu obliczono średnie, które następnie odjęto od siebie: 
```{r}
module <- median(MW)-median(M31)
module
```
Efektem będzie otrzymanie podobnego poziomu jasności, który jest obserwowalny w naszej Galaktyce. Wyniki porównania wykresów zostały przedstawione poniżej: 
```{r}
plot(ecdf(MW),cex.points=0,verticals=T, main="Empiryczne dystrybuanty", col="green")
plot(ecdf(M31+module),cex.points=0,verticals=T,add=T,main="Empiryczne dystrybuanty", col="red") 
legend(-8,0.2,legend = c("Droga Mleczna","M31"),col = c("green","red"),lty = 1,cex=0.8)
```

c) Wynik wartości **module** porównano z wynikiem testu rang Wilcoxon’a, który został obliczony poniżej: 
```{r}
wilcox.test(MW,M31+module)
```
Jak można zauważyć wartości wyznaczone za pomocą median oraz testu są zbliżone. Tak więc moża przyjąść, iż różnica median jako przesunięcie jest zadowalająco wystarczające. 

d) Q-Q -- wykres kwantyl-kwantyl służy między innymi do porównania, czy dystrybuancja danych jest zgodna z modelem. Dwuwymiarowy wykres zmiennych przedstawia punkty, które powstają na wykresie w wyniku dwóch odpowiadających sobie wartości kwantyli zmiennych losowych ich rozkładu. warto zauważyć, że jeśli wszystkie punkty odpowadają lini prostej to zmienne losowe na wykresie są opisane tym samym rozkładem. Procedura utworzenia wykresu przedstawia się następująco:  
\begin{itemize}
\item porządkowanie rosnąco residuł, które są kantylami empirycznymi,
\item obliczenie rzędów kwantyli,
\item obliczenie kwantyli teoretycznych,
\item sortowanie residuł rosnąco dla drugiego zestawu danych,
\item zestawienie kwantyli n wykresie. 
\end{itemize}

Poniżej zostały zaprezentowane wykresy kwantyl kwantyl:
```{r}
qqnorm(MW, pch=20, cex.axis=1.3, cex.lab=1.3, main="")
qqline(MW, lty=2, lwd=1.5)
```

Oś OY powyższego wykresu przedstawia empiryczną dystrybucję jasności gromad w Drodze Mlecznej, natomiast oś OX teoretyczną dystrybucję rozkładu normalnego. Jak można zauważyć kwantyle empiryczne zgadzają się z modelem teoretycznym.

```{r}
qqnorm(M31, pch=20, cex.axis=1.3, cex.lab=1.3, main="")
qqline(M31, lty=2, lwd=1.5)
```

Analogicznie jak poprzednio oś OY powyższego wykresu przedstawia empiryczną dystrybucję jasności gromad w M31, natomiast oś OX teoretyczną dystrybucję rozkładu normalnego. Można również zauważyć, iż model teoretyczny nie pokrywa się z niższymi wartościami.

Porównując dystrybuancję dwóch zestawów danych otrzymujemy nastepujący wykres:

```{r}
qqplot(M31,MW, pch=20, cex.axis=1.3, cex.lab=1.3, main="", xlab = "M31", ylab = "Droga Mleczna")
```

W powyższym przypadku na osiach są empiryczne dystrybucje jasności gromad w Drodze Mlecznej i w M31. Na powyższym rysunku możemy zaobserwować nieliniowy trend, który prowadzi do wniosku, iż rozkłady jasności obu galaktyk są różne. 

e) W celu potwierdzenia powyższego wniosku należy przeprowadzić nastepujący test:
```{r}
ks.test(MW, M31+module)
```
Statystyka testu została opisana w poprzednim zadaniu. Dla poziomu istotności $\alpha=0.05$ hioptezę należałoby odrzucić, ale ponieważ poziom istotności możemy przyjąść również na poziomie $\alpha=0.01$ nie mamy pewności co do poprawności odrzucenia hipotezy. 

\section{Zadanie 3}

a) Estymator zgodny, który jest nieobciążony oraz najefektywniejszy wartości przeciętnej to wartość średnia. Poniżej została przedstwiona wartość obliczonej średniej:
```{r include=FALSE}
library(MASS)
Height <- survey$Height 
```
```{r}
Estym <- mean(Height, na.rm = T)
Estym
```

b) Dla nieznanego odchylenia standargowego oraz nieznanej wartości przeciętnej stosujemy statystykę studenta. Szukam wartość błędu przy przedziale ufności 95%, gdzie  wykonuję następujące obliczenia:
```{r}
#rozkład studenta
s2 <- sd(Height, na.rm = T)
n <- length(Height)
t <- qt(0.975, n-1)
t
#przedział ufnosci 
Q1=qt(0.05/2, 237-1)*s2/sqrt(n)+ Estym 
Q1
Q2=qt(1-0.05/2, 237-1)*s2/sqrt(n)+ Estym
Q2
```
Ostatecznie przedziałem ufności jest wartość: $$[171.1207; 173.641],$$ natomiast wartość średnia wraz z błędem pochodzącym z tego przedziału to: $$172.38\pm 1.34 [cm].$$

c) W celu sprawdzenia hipotezy zerowej, czyli czy studenci palą niezależnie od ilości ćwiczeń zastosowano test chi-kwadrat. Statystyka opisująca ten test to:
\begin{equation}
\label{wz6}
\chi^2=\sum_{i=1}^r \sum_{k=1}^s \frac{(n_{ik}-n\cdot p_{ik})^2}{n\cdot p_{ik}},
\end{equation}
gdzie: $n_{ik}$ - liczności odpowiadające danej parze kategorii, r=3 -liczba kategorii częstotliwości palenia, s=4 - liczba kategorii częstości ćwiczeń, n - suma $n_{ik}$ oraz $p_{ik}$ które jest obliczane ze wzoru:
\begin{equation}
p_{ik}=p_{i.}p_{.k}=\frac{n_{i.}}{n}\cdot \frac{n_{.k}}{k}.
\label{wz7}
\end{equation}
W sumie tatystyka ma 6 stopni swobody, natomiast obszar krytyczny jest prawostronny. Otrzymano nastepujący wynik testu chi-kwadrat:
```{r include=FALSE}
Exer <- survey$Exer
Smoke <- survey$Smoke
Table_Smoke <- table(survey$Exer, survey$Smoke)
Table_Smoke
```
```{r}
chisq.test(Exer, Smoke)
```
Z wyniku testu można stwiedzić, iż dla poziomu istotności $\alpha=0.05$ nie mamy podstaw do odrzucenia hipotezy zerowej.
\section{Zadanie 4}
a)  W celu dopasowania regresji liniowej zostały wykonane następujące polecenia:
```{r}
x <- faithful$eruptions
y <- faithful$waiting
regline <- lm(x~y)
summary(regline)
plot(x~y, ylab = "Długość erupcji [min]", xlab = "Czas oczekiwania na następną erupcję [min]")
abline(regline,lwd=2,col=2)

```

Powyżej zostały przedstawione statystyki oraz wykres zależności długości erupcji od czasu oczekiwania na kolejną erupcję wraz z dopasowaną prostą za pomocą regresji liniowej. Wartościami parametrów dopasowania dla prostej:
\begin{equation}
y=a\cdot x + b,
\label{wz8}
\end{equation}
są między innymi: 
\begin{itemize}
\item $a=0.0756\pm 0.0023$,
\item $b=-1.87\pm 0.17.$
\end{itemize}

Do oszacowania czasu trwania następnej erupcji wykorzystano powyższy wzór wraz z współczynnikami dopasowania, gdzie $x=80$ min. Po podstawieniu otrzymano następujący wynik: $$4.18\pm 0.36.$$

b) Poniżej zostały wyrysowany wykres residuł dopasowanej regresji:
```{r}
plot(regline$residuals)
```

Jak moża zauażyć zastosowany model regresji liniowej jest poprawny, ponieważ dane są rozproszone oraz nie wykazują żadnego trendu. 

c)  Kryteria **Akaike** oraz **Bayesowskie** stosuje się w celu porównania zastosowanych modeli do danych. Wartości uzyskane z tych kryteriów są estymatorami błędu oraz zgodności próbek z modelem. Ich wartość może wskazać, który z modeli jest lepszym wyborem, gdzie niższa wartość oznacza, iż model dla poszczególnych danych jest lepszy. Poniżej zaprezentowano wartości tych kryteriów dla regresji liniowej. 

```{r}
AIC(regline)
BIC(regline)
```
d) Korzystając z 95% poziomu ufności średniego czasu trwania erupcji dla czasu 80 min zostały wyznaczone za pomocą funkcji predict wartości przewidywane y. Poniżej przedstawiono wyniki działania funkcji: 
```{r}
regline1 <- lm(eruptions~waiting,data=faithful)
time80=predict(regline1,data.frame(waiting=c(80)),interval = "confidence")
print(time80)
```

Ostatecznie odczytanym z powyższych wartości jest przedział ufności: $(4.1; 4.25)$.